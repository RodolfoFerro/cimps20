{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Empaquetado de modelos",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/cimps20/blob/main/notebooks/05-Empaquetado_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Empaquetado de modelos\n",
        "\n",
        "> **Rodolfo Ferro** <br>\n",
        "> Google Dev Expert en ML, 2020.\n",
        ">\n",
        "> _Redes:_\n",
        "> - GitHub - [RodolfoFerro](https://github.com/RodolfoFerro)\n",
        "> - Twitter - [@FerroRodolfo](https://twitter.com/FerroRodolfo)\n",
        "> - Instagram - [@rodo_ferro](https://instagram.com/rodo_ferro)\n",
        "\n",
        "## Contenidos\n",
        "\n",
        "#### **Sección VI**\n",
        "1. **Código:** Un nuevo problema\n",
        "2. **Código:** Guardado de modelos en TF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Sección VI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z7JrTygMDSx"
      },
      "source": [
        "### El dataset de dígitos escritos a mano\n",
        "\n",
        "Comencemos importando TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPB4nBh8MFDm"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p65n1ePSMYm8"
      },
      "source": [
        "Los datos de MNIST están disponibles directamente en la API de conjuntos de datos de `tf.keras` y podemos importarlos de la misma manera que hicimos ocn el de modas.\n",
        "\n",
        "Llamar a `load_data` en este objeto nos dará dos conjuntos con los valores de entrenamiento y prueba para los gráficos que contienen las prendas y sus etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgked3UaMJW4"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c0eSrlvMs6H"
      },
      "source": [
        "¿Cómo se ven estos valores?\n",
        "\n",
        "Imprimamos una imagen de entrenamiento y una etiqueta de entrenamiento para ver."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CdTltfNM0qF"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(linewidth=200)\n",
        "\n",
        "\n",
        "# Set index of image to be seen\n",
        "img_index = 0\n",
        "\n",
        "# Plot image\n",
        "plt.imshow(training_images[img_index], cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", training_labels[img_index])\n",
        "print(\"Matrix:\\n\", training_images[img_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxfNdPU3NQge"
      },
      "source": [
        "### Preparación de los datos\n",
        "\n",
        "Notarás que todos los valores están entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es más fácil si transformamos los valores para tratar todos con valores entre 0 y 1. Este proceso se llama **normalización**.\n",
        "\n",
        "Además, para este proceso añadiremos la expansión de dimensiones para poder alimentar a la red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWoPQWCGNdnB"
      },
      "source": [
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images / 255.0\n",
        "\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTaT1RjyNjqV"
      },
      "source": [
        "### Creación del modelo\n",
        "\n",
        "Podemos hacer uso del potencial de una red neuronal convolucional. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIbaxGZ5UgMJ"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Añadamos algunas capas convolucionales extra\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwkxtrHdNvHg"
      },
      "source": [
        "### Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybq9AzJiN8ZV"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH9mfZMTN8_H"
      },
      "source": [
        "### Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHCV5BrAN-pq"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-hQX4NNOd_D"
      },
      "source": [
        "### Predicción\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaDFuXyROfZY"
      },
      "source": [
        "test_index = 30\n",
        "\n",
        "plt.imshow(np.squeeze(test_images[test_index]), cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", test_labels[test_index])\n",
        "prediction = model.predict(np.expand_dims(test_images[test_index], axis=0))\n",
        "print(\"Prediction:\", np.argmax(prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBShUhNCzp96"
      },
      "source": [
        "### Guardado del modelo entrenado\n",
        "\n",
        "Lo que haremos será guardar los pesos y la arquitectura del modelo en 2 archivos distintos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKsqcQn1fUDV"
      },
      "source": [
        "# Serialize model to JSON:\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Serialize weights to HDF5 (h5py needed):\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Model saved to disk.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwOO8Fufzzi4"
      },
      "source": [
        "Los mismos archivos pueden ser cargados utilizando las funciones correspondientes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_pm6s7z4EE"
      },
      "source": [
        "# Load json and create model:\n",
        "model_from_json = tf.keras.models.model_from_json\n",
        "\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# Load weights into loaded model:\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Model loaded from disk.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJFoDwrv05oN"
      },
      "source": [
        "Ejemplo de predicción con el modelo cargado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4k8hHD20ou1"
      },
      "source": [
        "test_index = 30\n",
        "\n",
        "plt.imshow(np.squeeze(test_images[test_index]), cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", test_labels[test_index])\n",
        "prediction = loaded_model.predict(np.expand_dims(test_images[test_index], axis=0))\n",
        "print(\"Prediction:\", np.argmax(prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfAtdFtz0-S0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}